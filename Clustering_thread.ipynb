{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EYoFygbzgqBF",
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 60em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7618\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import skimage\n",
    "import skimage.io as io\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import minimize_scalar\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import threading\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import optuna\n",
    "import time\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 60em; }</style>\"))\n",
    "\n",
    "SCALE = False\n",
    "TEST_SIZE = 500\n",
    "\n",
    "EPS_MIN = 0.01\n",
    "EPS_MAX = 4\n",
    "TIMEOUT = 120\n",
    "\n",
    "Q = None\n",
    "EPS = None\n",
    "\n",
    "\n",
    "ic = io.imread_collection('data/*.png', conserve_memory=False)\n",
    "print(len(ic))\n",
    "#io.imshow_collection(ic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Filename      Cluster\n",
      "0       1_18-41.png        1like\n",
      "1       1_18-96.png  @toolong129\n",
      "2      1_18-174.png            T\n",
      "3      1_19-204.png            S\n",
      "4      1_19-229.png            r\n",
      "...             ...          ...\n",
      "7613  7_521-166.png            r\n",
      "7614  7_521-241.png            S\n",
      "7615  7_522-189.png            t\n",
      "7616   7_523-19.png       0PLAMY\n",
      "7617   7_523-95.png       0PLAMY\n",
      "\n",
      "[7618 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#For test\n",
    "correct_df = pd.read_csv('data/@0CLUSTERING.csv')\n",
    "print(correct_df)\n",
    "\n",
    "correct = list(correct_df[\"Cluster\"])\n",
    "\n",
    "#correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "initial_df = pd.DataFrame(dtype=object)\n",
    "initial_df[0] = ic\n",
    "initial_df[1] = correct\n",
    "\n",
    "initial_df[0] = pd.DataFrame(initial_df.apply(lambda row: skimage.color.rgb2gray(row[0]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_prep(df, scale):\n",
    "    #print(df.apply(lambda row: ndi.sum_labels(row[0]),axis=1))\n",
    "    max_sum = max(df.apply(lambda row: ndi.sum_labels(row[0]),axis=1))\n",
    "    #print(max_sum)\n",
    "    \n",
    "    def get_max_shape(df):\n",
    "        shape_y = max(df.apply(lambda row: row[0].shape[0], axis=1))\n",
    "        shape_x = max(df.apply(lambda row: row[0].shape[1], axis=1))\n",
    "        return shape_y, shape_x\n",
    "    \n",
    "    if scale:\n",
    "        def img_scale(img):\n",
    "            my_sum = ndi.sum_labels(img)\n",
    "            return ndi.zoom(img, np.sqrt(max_sum/my_sum), cval=1.)\n",
    "\n",
    "        df[0] = df.apply(lambda row: img_scale(row[0]), axis=1)\n",
    "        #print(df.apply(lambda row: ndi.sum_labels(row[0]),axis=1))\n",
    "\n",
    "    def img_pre(img):\n",
    "        cy, cx = ndi.center_of_mass(img)\n",
    "        cy = round(cy)\n",
    "        cx = round(cx)\n",
    "        sy, sx = img.shape\n",
    "        top = max(sy - 1 - cy - cy, 0)\n",
    "        bot = max(cy - (sy - 1 - cy), 0)\n",
    "        left = max(sx - 1 - cx - cx, 0)\n",
    "        right = max(cx - (sx - 1 - cx), 0)\n",
    "        return cv2.copyMakeBorder(img, top, bot, left, right, cv2.BORDER_CONSTANT, None, value=1.)\n",
    "\n",
    "    df[0] = df.apply(lambda row: img_pre(row[0]), axis=1)\n",
    "    #print(get_max_shape(df))\n",
    "\n",
    "    max_shape_y, max_shape_x = get_max_shape(df)\n",
    "\n",
    "    def img_post(img):\n",
    "        sy, sx = img.shape\n",
    "        top = (max_shape_y - sy) // 2\n",
    "        bot = (max_shape_y - sy + 1) // 2\n",
    "        left = (max_shape_x - sx) // 2\n",
    "        right = (max_shape_x - sx + 1) // 2\n",
    "        return cv2.copyMakeBorder(img, top, bot, left, right, cv2.BORDER_CONSTANT, None, value=1.)\n",
    "\n",
    "    df[0] = df.apply(lambda row: img_post(row[0]), axis=1)\n",
    "    #print(get_max_shape(df))\n",
    "    \n",
    "    df[0] = df.apply(lambda row: np.reshape(row[0], -1), axis=1)\n",
    "\n",
    "data_prep(initial_df, SCALE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_subsets(df):\n",
    "    ind = list(df.index)\n",
    "    np.random.shuffle(ind)\n",
    "    ind1 = ind[:TEST_SIZE]\n",
    "    ind2 = ind[len(df) - TEST_SIZE:]\n",
    "    np.random.shuffle(ind1)\n",
    "    np.random.shuffle(ind2)\n",
    "    return [pd.DataFrame(df, index=ind1, copy=False),\n",
    "            pd.DataFrame(df, index=ind2, copy=False)]\n",
    "\n",
    "def get_subset(df):\n",
    "    sub, _ = get_subsets(df)\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clustering(eps, q, data):\n",
    "    print(f\"started clustering({eps}, {q})\")\n",
    "    if np.isclose(q, 0):\n",
    "        p = np.inf\n",
    "    else:\n",
    "        p = 1 / q\n",
    "    \n",
    "    if np.isclose(p, 2):\n",
    "        p = 2\n",
    "    \n",
    "    start = time.time()\n",
    "    _, labels = cluster.dbscan(data, eps=eps, p=p, min_samples=1)\n",
    "    stop = time.time()\n",
    "    print(f\"clustering({eps}, {q}) finished, time: {stop - start}\")\n",
    "    #dbscan.fit(data)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_plot(data_x, y):\n",
    "    if not SCALE:\n",
    "        pca = PCA(n_components = 2)\n",
    "        data2D = pca.fit_transform(data_x)\n",
    "        print(f\"nr of classes: {len(set(y))}\")\n",
    "        fig = px.scatter(x=data2D[:, 0], y=data2D[:, 1], color=[str(v) for v in y], width=900, height=600)\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(f\"{SCALE=}, plot not shown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def objective(eps, q):\n",
    "    acc = []\n",
    "    for test_df in get_subsets(initial_df):\n",
    "        data = list(test_df[0])\n",
    "        correct = list(test_df[1])\n",
    "        res = clustering(eps, q, data)\n",
    "        acc.append(metrics.adjusted_rand_score(correct, res))\n",
    "\n",
    "    with open(\"{}.pickle\".format*trial.number, \"wb)\") as fout:\n",
    "        pickle.dump(res, fout)\n",
    "    return np.mean(acc)\n",
    "\n",
    "def show_objective_plot(up_bound, num):\n",
    "    x = np.linspace(0.001, up_bound, num=num)\n",
    "    objective_vec = np.vectorize(objective)\n",
    "    y = objective_vec(x)\n",
    "    fig = px.scatter(x=x, y=y, width=900, height=600)\n",
    "    fig.show()\n",
    "\n",
    "#show_objective_plot(4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def check_clustering(eps, q):\n",
    "    test_df = get_subset(initial_df)\n",
    "    data = list(test_df[0])\n",
    "    correct = list(test_df[1])\n",
    "    res = clustering(eps, q, data)\n",
    "    acc = metrics.adjusted_rand_score(correct, res)\n",
    "    \n",
    "    print(\"correct clustering\")\n",
    "    show_plot(data, correct)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(f\"found clustering\")\n",
    "    print(f\"eps: {float(eps)}\")\n",
    "    print(f\"q: {float(q)}\")\n",
    "    print(f\"ACCURACY: {metrics.rand_score(correct, res)}\")\n",
    "    print(f\"BALANCE ACCURACY: {acc}\")\n",
    "    \n",
    "    acc1 = objective(eps, q)\n",
    "    \n",
    "    print(f\"AVERAGE BALANCED ACCURACY: {np.mean([acc1, acc1, acc])}\")\n",
    "    \n",
    "    show_plot(data, res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#%time\n",
    "#_, labels = cluster.dbscan(list(initial_df.loc[:10, 0]), eps=1, p=2, min_samples=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#check_clustering(2.3, 1/3) #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_all_data():\n",
    "    print(\"all data\")\n",
    "    show_plot(list(initial_df[0]), list(initial_df[1]))\n",
    "\n",
    "show_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def objective_optuna(trial):\n",
    "    eps = trial.suggest_float(\"eps\", EPS_MIN, EPS_MAX)\n",
    "    q = trial.suggest_float(\"q\", 0, 1)\n",
    "    return objective(eps, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_params_optuna(timeout):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    fixed_params = {key: val for key, val in [(\"q\", Q), (\"eps\", EPS)] if val is not None}\n",
    "    study.sampler = optuna.samplers.PartialFixedSampler(fixed_params, study.sampler)\n",
    "    \n",
    "    study.optimize(objective_optuna, timeout=timeout)\n",
    "    optuna.visualization.plot_slice(study).show()\n",
    "    optuna.visualization.plot_contour(study, params=[\"q\", \"eps\"]).show()\n",
    "    optuna.visualization.plot_param_importances(study).show()\n",
    "    return study.best_trial.params[\"eps\"], study.best_trial.params[\"q\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#print(initial_df)\n",
    "def get_best_params():\n",
    "    return get_best_params_optuna(TIMEOUT)\n",
    "\n",
    "best_eps, best_q = get_best_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_study():\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"ml_clustering\", storage=)\n",
    "\n",
    "    fixed_params = {key: val for key, val in [(\"q\", Q), (\"eps\", EPS)] if val is not None}\n",
    "    study.sampler = optuna.samplers.PartialFixedSampler(fixed_params, study.sampler)\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def thread_optimization(study, timeout=TIMEOUT):\n",
    "    fixed_params = {key: val for key, val in [(\"q\", Q), (\"eps\", EPS)] if val is not None}\n",
    "    study.sampler = optuna.samplers.PartialFixedSampler(fixed_params, study.sampler)\n",
    "\n",
    "    study.optimize(objective_optuna, timeout=timeout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in CPU:\n",
    "    proc = threading.Thread(target=thread_optimization, args=[study]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from scipy.optimize import shgo, dual_annealing, differential_evolution, basinhopping\n",
    "\n",
    "#for f in [dual_annealing, differential_evolution]:\n",
    "#    res = f(lambda eps: -objective(eps), [(1.5, 3.5)], maxiter=100)\n",
    "#    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check_clustering(best_eps, best_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}