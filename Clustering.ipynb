{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import skimage\n",
    "import skimage.io as io\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import minimize_scalar\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 60em; }</style>\"))\n",
    "\n",
    "SCALE = False\n",
    "TEST_SIZE = 5000\n",
    "\n",
    "ic = io.imread_collection('data/*.png', conserve_memory=False)\n",
    "print(len(ic))\n",
    "#io.imshow_collection(ic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#For test\n",
    "correct_df = pd.read_csv('data/@0CLUSTERING.csv')\n",
    "print(correct_df)\n",
    "\n",
    "correct = list(correct_df[\"Cluster\"])\n",
    "\n",
    "#correct"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "initial_df = pd.DataFrame(dtype=object)\n",
    "initial_df[0] = ic\n",
    "initial_df[1] = correct\n",
    "\n",
    "initial_df[0] = pd.DataFrame(initial_df.apply(lambda row: skimage.color.rgb2gray(row[0]), axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def data_prep(df, scale):\n",
    "    #print(df.apply(lambda row: ndi.sum_labels(row[0]),axis=1))\n",
    "    max_sum = max(df.apply(lambda row: ndi.sum_labels(row[0]),axis=1))\n",
    "    #print(max_sum)\n",
    "    \n",
    "    def get_max_shape(df):\n",
    "        shape_y = max(df.apply(lambda row: row[0].shape[0], axis=1))\n",
    "        shape_x = max(df.apply(lambda row: row[0].shape[1], axis=1))\n",
    "        return shape_y, shape_x\n",
    "    \n",
    "    if scale:\n",
    "        def img_scale(img):\n",
    "            my_sum = ndi.sum_labels(img)\n",
    "            return ndi.zoom(img, np.sqrt(max_sum/my_sum), cval=1.)\n",
    "\n",
    "        df[0] = df.apply(lambda row: img_scale(row[0]), axis=1)\n",
    "        #print(df.apply(lambda row: ndi.sum_labels(row[0]),axis=1))\n",
    "\n",
    "    def img_pre(img):\n",
    "        cy, cx = ndi.center_of_mass(img)\n",
    "        cy = round(cy)\n",
    "        cx = round(cx)\n",
    "        sy, sx = img.shape\n",
    "        top = max(sy - 1 - cy - cy, 0)\n",
    "        bot = max(cy - (sy - 1 - cy), 0)\n",
    "        left = max(sx - 1 - cx - cx, 0)\n",
    "        right = max(cx - (sx - 1 - cx), 0)\n",
    "        return cv2.copyMakeBorder(img, top, bot, left, right, cv2.BORDER_CONSTANT, None, value=1.)\n",
    "\n",
    "    df[0] = df.apply(lambda row: img_pre(row[0]), axis=1)\n",
    "    #print(get_max_shape(df))\n",
    "\n",
    "    max_shape_y, max_shape_x = get_max_shape(df)\n",
    "\n",
    "    def img_post(img):\n",
    "        sy, sx = img.shape\n",
    "        top = (max_shape_y - sy) // 2\n",
    "        bot = (max_shape_y - sy + 1) // 2\n",
    "        left = (max_shape_x - sx) // 2\n",
    "        right = (max_shape_x - sx + 1) // 2\n",
    "        return cv2.copyMakeBorder(img, top, bot, left, right, cv2.BORDER_CONSTANT, None, value=1.)\n",
    "\n",
    "    df[0] = df.apply(lambda row: img_post(row[0]), axis=1)\n",
    "    #print(get_max_shape(df))\n",
    "    \n",
    "    df[0] = df.apply(lambda row: np.reshape(row[0], -1), axis=1)\n",
    "\n",
    "data_prep(initial_df, SCALE)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_subsets(df):\n",
    "    ind = list(df.index)\n",
    "    np.random.shuffle(ind)\n",
    "    ind1 = ind[:TEST_SIZE]\n",
    "    ind2 = ind[len(df) - TEST_SIZE:]\n",
    "    np.random.shuffle(ind1)\n",
    "    np.random.shuffle(ind2)\n",
    "    return [pd.DataFrame(df, index=ind1, copy=False),\n",
    "            pd.DataFrame(df, index=ind2, copy=False)]\n",
    "\n",
    "def get_subset(df):\n",
    "    sub, _ = get_subsets(df)\n",
    "    return sub"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clustering(eps, data):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=1)\n",
    "    dbscan.fit(data)\n",
    "    return dbscan.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_plot(data_x, y):\n",
    "    if not SCALE:\n",
    "        pca = PCA(n_components = 2)\n",
    "        data2D = pca.fit_transform(data_x)\n",
    "        print(f\"nr of classes: {len(set(y))}\")\n",
    "        fig = px.scatter(x=data2D[:, 0], y=data2D[:, 1], color=[str(v) for v in y], width=900, height=600)\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(f\"{SCALE=}, plot not shown\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(eps):\n",
    "    acc = []\n",
    "    for test_df in get_subsets(initial_df):\n",
    "        data = list(test_df[0])\n",
    "        correct = list(test_df[1])\n",
    "        res = clustering(eps, data)\n",
    "        acc.append(metrics.adjusted_rand_score(correct, res))\n",
    "    return np.mean(acc)\n",
    "\n",
    "def show_objective_plot(up_bound, num):\n",
    "    x = np.linspace(0.001, up_bound, num=num)\n",
    "    objective_vec = np.vectorize(objective)\n",
    "    y = objective_vec(x)\n",
    "    fig = px.scatter(x=x, y=y, width=900, height=600)\n",
    "    fig.show()\n",
    "\n",
    "show_objective_plot(4, 100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def check_clustering(eps):\n",
    "    test_df = get_subset(initial_df)\n",
    "    data = list(test_df[0])\n",
    "    correct = list(test_df[1])\n",
    "    res = clustering(eps, data)\n",
    "    acc = metrics.adjusted_rand_score(correct, res)\n",
    "    \n",
    "    print(\"correct clustering\")\n",
    "    show_plot(data, correct)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(f\"found clustering\")\n",
    "    print(f\"eps: {float(eps)}\")\n",
    "    print(f\"ACCURACY: {metrics.rand_score(correct, res)}\")\n",
    "    print(f\"BALANCE ACCURACY: {acc}\")\n",
    "    \n",
    "    acc1, acc2 = objective(eps), objective(eps)\n",
    "    \n",
    "    print(f\"AVERAGE BALANCED ACCURACY: {np.mean(acc1, acc1, acc2, acc2, acc)})\n",
    "    \n",
    "    show_plot(data, res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(initial_df)\n",
    "def get_best_eps():\n",
    "    res = minimize_scalar(lambda eps: -objective(eps), method=\"bounded\", bounds=(0.01, 4))\n",
    "    return res.x\n",
    "#print(res)\n",
    "\n",
    "best_eps = get_best_eps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.optimize import shgo, dual_annealing, differential_evolution, basinhopping\n",
    "\n",
    "#for f in [dual_annealing, differential_evolution]:\n",
    "#    res = f(lambda eps: -objective(eps), [(1.5, 3.5)], maxiter=100)\n",
    "#    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_clustering(best_eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"old balanced acc: 0.8369728801063364\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}